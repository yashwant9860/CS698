{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLRlvTV5aleT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2be21ec-65d6-4d13-91ef-8b28aff55bd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'indic_nlp_library'...\n",
            "remote: Enumerating objects: 1399, done.\u001b[K\n",
            "remote: Counting objects: 100% (180/180), done.\u001b[K\n",
            "remote: Compressing objects: 100% (57/57), done.\u001b[K\n",
            "remote: Total 1399 (delta 135), reused 147 (delta 120), pack-reused 1219\u001b[K\n",
            "Receiving objects: 100% (1399/1399), 9.57 MiB | 11.46 MiB/s, done.\n",
            "Resolving deltas: 100% (745/745), done.\n",
            "Cloning into 'indic_nlp_resources'...\n",
            "remote: Enumerating objects: 139, done.\u001b[K\n",
            "remote: Counting objects: 100% (13/13), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 139 (delta 2), reused 2 (delta 0), pack-reused 126\u001b[K\n",
            "Receiving objects: 100% (139/139), 149.77 MiB | 19.66 MiB/s, done.\n",
            "Resolving deltas: 100% (53/53), done.\n",
            "Updating files: 100% (28/28), done.\n",
            "Collecting Morfessor\n",
            "  Downloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\n",
            "Installing collected packages: Morfessor\n",
            "Successfully installed Morfessor-2.0.6\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# import nltk\n",
        "# nltk.download('punkt')\n",
        "import time\n",
        "import math\n",
        "import string\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from typing import Iterable, List\n",
        "from torch import Tensor\n",
        "from torch.nn import Transformer\n",
        "import re\n",
        "import csv\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "!git clone \"https://github.com/anoopkunchukuttan/indic_nlp_library\"\n",
        "!git clone https://github.com/anoopkunchukuttan/indic_nlp_resources.git\n",
        "!pip install Morfessor\n",
        "# The path to the local git repo for Indic NLP library\n",
        "INDIC_NLP_LIB_HOME=r\"/content/indic_nlp_library\"\n",
        "\n",
        "# The path to the local git repo for Indic NLP Resources\n",
        "INDIC_NLP_RESOURCES=\"/content/indic_nlp_resources\"\n",
        "import sys\n",
        "sys.path.append(r'{}'.format(INDIC_NLP_LIB_HOME))\n",
        "from indicnlp import common\n",
        "common.set_resources_path(INDIC_NLP_RESOURCES)\n",
        "from indicnlp import loader\n",
        "loader.load()\n",
        "from indicnlp.tokenize import indic_tokenize\n",
        "import indicnlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGvxMjPALf1-"
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH=20\n",
        "LANGUAGES = ['Kannada','Hindi','Bengali','Gujarati','Telgu','Malayalam','Tamil',]\n",
        "z = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JUpl1-JbPVF",
        "outputId": "2812645c-b96d-4678-a2b2-6aee85767c2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7IG5-cyFbhlZ"
      },
      "outputs": [],
      "source": [
        "def normalizeString(s):\n",
        "    s = s.lower().strip()\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    translator = str.maketrans('', '', string.punctuation + \"\\\"'\")\n",
        "    s = s.translate(translator)\n",
        "    return s.strip()\n",
        "\n",
        "def extract_data(language,filepath):\n",
        "  with open(filepath, 'r') as file:\n",
        "    data=json.load(file)\n",
        "  source_sentences = []\n",
        "  target_sentences = []\n",
        "  id = []\n",
        "  for language_pair, language_data in data.items():\n",
        "      print(f\"Language Pair: {language_pair}\")\n",
        "      if(language_pair==f'English-{language}'):\n",
        "        for data_type, data_entries in language_data.items():\n",
        "            print(f\"  Data Type: {data_type}\")\n",
        "            for entry_id, entry_data in data_entries.items():\n",
        "              source_sentences.append(normalizeString(entry_data[\"source\"]))\n",
        "              if \"target\" in entry_data:\n",
        "                target_sentences.append(normalizeString(entry_data[\"target\"]))\n",
        "              id.append(entry_id)\n",
        "  return source_sentences,target_sentences,id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGsK0fmBubv5",
        "outputId": "70ace29c-932d-49ae-d5f3-51eaf715acc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Language Pair: English-Bengali\n",
            "Language Pair: English-Gujarati\n",
            "Language Pair: English-Hindi\n",
            "Language Pair: English-Kannada\n",
            "  Data Type: Train\n",
            "Language Pair: English-Malayalam\n",
            "Language Pair: English-Tamil\n",
            "Language Pair: English-Telgu\n"
          ]
        }
      ],
      "source": [
        "source_sentence,target_sentence,id = extract_data(LANGUAGES[z] , '/content/drive/MyDrive/drive/train_data2.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnbDs9pD9NkP",
        "outputId": "38c20683-66f7-4f05-8bcc-aa4446a82153"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['ಅವರು ಒಂದೇ ಮಾರುಕಟ್ಟೆಯ ಸ್ಥಳದಲ್ಲಿ ಸಮೀಪದ ಐದು ಮಾರುಕಟ್ಟೆಗಳ ಇರುವಿಕೆಯನ್ನು ಒಪ್ಪಿಕೊಂಡಿದ್ದಾರೆ'],\n",
              " ['at the place of lone market he has considered the presence of five nearby markets'],\n",
              " ['563224'],\n",
              " 46794,\n",
              " 46794)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "source_sentence[:1],target_sentence[:1],id[:1],len(source_sentence),len(target_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZgKvaC80LV3"
      },
      "outputs": [],
      "source": [
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, list1, list2):\n",
        "        self.list1 = list1\n",
        "        self.list2 = list2\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.list1)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        concatenated_item = (self.list1[idx], self.list2[idx])\n",
        "        return concatenated_item\n",
        "\n",
        "SRC_LANGUAGE = LANGUAGES[z]\n",
        "TGT_LANGUAGE = 'English'\n",
        "\n",
        "# Place-holders\n",
        "token_transform = {}\n",
        "vocab_transform = {}\n",
        "class tokens():\n",
        "  def __init__(self,lang):\n",
        "    self.lang=lang\n",
        "  def __call__(self, data):\n",
        "    return indic_tokenize.trivial_tokenize(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jeYL1FB_whdm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ca5483e-4bc9-4c62-c726-d9df79274a8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchtext/data/utils.py:105: UserWarning: Spacy model \"en\" could not be loaded, trying \"en_core_web_sm\" instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Language Pair: English-Bengali\n",
            "Language Pair: English-Gujarati\n",
            "Language Pair: English-Hindi\n",
            "Language Pair: English-Kannada\n",
            "  Data Type: Train\n",
            "Language Pair: English-Malayalam\n",
            "Language Pair: English-Tamil\n",
            "Language Pair: English-Telgu\n",
            "Language Pair: English-Bengali\n",
            "Language Pair: English-Gujarati\n",
            "Language Pair: English-Hindi\n",
            "  Data Type: Train\n",
            "Language Pair: English-Kannada\n",
            "Language Pair: English-Malayalam\n",
            "Language Pair: English-Tamil\n",
            "Language Pair: English-Telgu\n",
            "Language Pair: English-Bengali\n",
            "  Data Type: Train\n",
            "Language Pair: English-Gujarati\n",
            "Language Pair: English-Hindi\n",
            "Language Pair: English-Kannada\n",
            "Language Pair: English-Malayalam\n",
            "Language Pair: English-Tamil\n",
            "Language Pair: English-Telgu\n",
            "Language Pair: English-Bengali\n",
            "Language Pair: English-Gujarati\n",
            "  Data Type: Train\n",
            "Language Pair: English-Hindi\n",
            "Language Pair: English-Kannada\n",
            "Language Pair: English-Malayalam\n",
            "Language Pair: English-Tamil\n",
            "Language Pair: English-Telgu\n",
            "Language Pair: English-Bengali\n",
            "Language Pair: English-Gujarati\n",
            "Language Pair: English-Hindi\n",
            "Language Pair: English-Kannada\n",
            "Language Pair: English-Malayalam\n",
            "Language Pair: English-Tamil\n",
            "Language Pair: English-Telgu\n",
            "  Data Type: Train\n",
            "Language Pair: English-Bengali\n",
            "Language Pair: English-Gujarati\n",
            "Language Pair: English-Hindi\n",
            "Language Pair: English-Kannada\n",
            "Language Pair: English-Malayalam\n",
            "  Data Type: Train\n",
            "Language Pair: English-Tamil\n",
            "Language Pair: English-Telgu\n",
            "Language Pair: English-Bengali\n",
            "Language Pair: English-Gujarati\n",
            "Language Pair: English-Hindi\n",
            "Language Pair: English-Kannada\n",
            "Language Pair: English-Malayalam\n",
            "Language Pair: English-Tamil\n",
            "  Data Type: Train\n",
            "Language Pair: English-Telgu\n"
          ]
        }
      ],
      "source": [
        "token_transform[SRC_LANGUAGE] = get_tokenizer('spacy')\n",
        "# token_transform[TGT_LANGUAGE] = get_tokenizer('spacy')\n",
        "token_transform[TGT_LANGUAGE] = tokens(LANGUAGES[z])\n",
        "def yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n",
        "    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n",
        "\n",
        "    for data_sample in data_iter:\n",
        "        yield token_transform[language](data_sample)\n",
        "\n",
        "\n",
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "\n",
        "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
        "\n",
        "# for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "train_iter_src,train_iter_tgt=[],[]\n",
        "for t in range(7):\n",
        "  iter_src,iter_tgt,id =extract_data(LANGUAGES[t] , '/content/drive/MyDrive/drive/train_data2.json')\n",
        "  train_iter_src.extend(iter_src)\n",
        "  train_iter_tgt.extend(iter_tgt)\n",
        "# Create torchtext's Vocab object\n",
        "vocab_transform[SRC_LANGUAGE] = build_vocab_from_iterator(yield_tokens(train_iter_src,SRC_LANGUAGE ),\n",
        "                                                min_freq=2,\n",
        "                                                specials=special_symbols,\n",
        "                                                special_first=True)\n",
        "vocab_transform[TGT_LANGUAGE] = build_vocab_from_iterator(yield_tokens(train_iter_tgt, TGT_LANGUAGE),\n",
        "                                                min_freq=2,\n",
        "                                                specials=special_symbols,\n",
        "                                                special_first=True)\n",
        "# Set ``UNK_IDX`` as the default index. This index is returned when the token is not found.\n",
        "# If not set, it throws ``RuntimeError`` when the queried token is not found in the Vocabulary.\n",
        "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "  vocab_transform[ln].set_default_index(UNK_IDX)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylisXMi63kNG",
        "outputId": "6c0ff92e-2e67-4bf5-b8eb-5db9c1a832e1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(264511, 75732)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "len(vocab_transform[SRC_LANGUAGE]),len(vocab_transform[TGT_LANGUAGE])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJBRBPUY70KN"
      },
      "outputs": [],
      "source": [
        "from torch import Tensor\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import Transformer\n",
        "import math\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# helper Module that adds positional encoding to the token embedding to introduce a notion of word order.\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self,\n",
        "                 emb_size: int,\n",
        "                 dropout: float,\n",
        "                 maxlen: int = 5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
        "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
        "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
        "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
        "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
        "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer('pos_embedding', pos_embedding)\n",
        "\n",
        "    def forward(self, token_embedding: Tensor):\n",
        "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
        "\n",
        "# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\n",
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size: int, emb_size):\n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
        "        self.emb_size = emb_size\n",
        "\n",
        "    def forward(self, tokens: Tensor):\n",
        "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
        "\n",
        "# Seq2Seq Network\n",
        "class Seq2SeqTransformer(nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_encoder_layers: int,\n",
        "                 num_decoder_layers: int,\n",
        "                 emb_size: int,\n",
        "                 nhead: int,\n",
        "                 src_vocab_size: int,\n",
        "                 tgt_vocab_size: int,\n",
        "                 dim_feedforward: int = 512,\n",
        "                 dropout: float = 0.1):\n",
        "        super(Seq2SeqTransformer, self).__init__()\n",
        "        self.transformer = Transformer(d_model=emb_size,\n",
        "                                       nhead=nhead,\n",
        "                                       num_encoder_layers=num_encoder_layers,\n",
        "                                       num_decoder_layers=num_decoder_layers,\n",
        "                                       dim_feedforward=dim_feedforward,\n",
        "                                       dropout=dropout)\n",
        "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
        "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
        "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
        "        self.positional_encoding = PositionalEncoding(\n",
        "            emb_size, dropout=dropout)\n",
        "\n",
        "    def forward(self,\n",
        "                src: Tensor,\n",
        "                trg: Tensor,\n",
        "                src_mask: Tensor,\n",
        "                tgt_mask: Tensor,\n",
        "                src_padding_mask: Tensor,\n",
        "                tgt_padding_mask: Tensor,\n",
        "                memory_key_padding_mask: Tensor):\n",
        "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
        "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
        "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n",
        "                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
        "        return self.generator(outs)\n",
        "\n",
        "    def encode(self, src: Tensor, src_mask: Tensor):\n",
        "        return self.transformer.encoder(self.positional_encoding(\n",
        "                            self.src_tok_emb(src)), src_mask)\n",
        "\n",
        "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
        "        return self.transformer.decoder(self.positional_encoding(\n",
        "                          self.tgt_tok_emb(tgt)), memory,\n",
        "                          tgt_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYH76hDd8DHZ"
      },
      "outputs": [],
      "source": [
        "def generate_square_subsequent_mask(sz):\n",
        "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
        "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "    return mask\n",
        "\n",
        "\n",
        "def create_mask(src, tgt):\n",
        "    src_seq_len = src.shape[0]\n",
        "    tgt_seq_len = tgt.shape[0]\n",
        "\n",
        "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
        "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
        "\n",
        "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
        "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
        "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q46SKpUH8MtR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38c20eaa-7408-48a5-d929-90ac38f89c2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n",
        "TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n",
        "EMB_SIZE =128\n",
        "NHEAD = 4\n",
        "FFN_HID_DIM = 128\n",
        "BATCH_SIZE = 8\n",
        "NUM_ENCODER_LAYERS = 3\n",
        "NUM_DECODER_LAYERS = 3\n",
        "\n",
        "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
        "                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
        "\n",
        "for p in transformer.parameters():\n",
        "    if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)\n",
        "\n",
        "transformer = transformer.to(DEVICE)\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "\n",
        "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WaXYXiGM8O9G"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# helper function to club together sequential operations\n",
        "def sequential_transforms(*transforms):\n",
        "    def func(txt_input):\n",
        "        for transform in transforms:\n",
        "            txt_input = transform(txt_input)\n",
        "        return txt_input\n",
        "    return func\n",
        "\n",
        "# function to add BOS/EOS and create tensor for input sequence indices\n",
        "def tensor_transform(token_ids: List[int]):\n",
        "    return torch.cat((torch.tensor([BOS_IDX]),\n",
        "                      torch.tensor(token_ids),\n",
        "                      torch.tensor([EOS_IDX])))\n",
        "\n",
        "# ``src`` and ``tgt`` language text transforms to convert raw strings into tensors indices\n",
        "text_transform = {}\n",
        "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "    text_transform[ln] = sequential_transforms(token_transform[ln], #Tokenization\n",
        "                                               vocab_transform[ln], #Numericalization\n",
        "                                               tensor_transform) # Add BOS/EOS and create tensor\n",
        "\n",
        "\n",
        "# function to collate data samples into batch tensors\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = [], []\n",
        "    for src_sample, tgt_sample in batch:\n",
        "        src_batch.append(src_sample)\n",
        "        tgt_batch.append(tgt_sample)\n",
        "\n",
        "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
        "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
        "    return src_batch, tgt_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2upOUl7i8R-p",
        "outputId": "8adba051-a025-4c36-c768-5bb6d06cd4ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "401243\n",
            "355348\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "# train_iter_src,train_iter_tgt,id = source_sentence,target_sentence,id = extract_data(LANGUAGES[z] , '/content/drive/MyDrive/drive/train_data2.json')\n",
        "print(len(train_iter_src))\n",
        "def final_data(train_src,train_tgt):\n",
        "    train_x=[]\n",
        "    train_y=[]\n",
        "    for x,y in zip(train_src,train_tgt):\n",
        "      x=text_transform[SRC_LANGUAGE](x.rstrip(\"\\n\"))\n",
        "      y=text_transform[TGT_LANGUAGE](y.rstrip(\"\\n\"))\n",
        "      len_x=len(x)\n",
        "      len_y=len(y)\n",
        "      x1=x\n",
        "      y1=y\n",
        "      zeros_x = np.count_nonzero(x1.numpy() == 0.0)\n",
        "      zeros_y = np.count_nonzero(y1.numpy() == 0.0)\n",
        "      if zeros_x/len_x<0.2 and zeros_y/len_y<0.2:\n",
        "        train_x.append(x)\n",
        "        train_y.append(y)\n",
        "    return train_x,train_y\n",
        "train_iter_src,train_iter_tgt=final_data(train_iter_src,train_iter_tgt)\n",
        "print(len(train_iter_src))\n",
        "train_iter = CustomDataset(train_iter_src,train_iter_tgt )\n",
        "def train_epoch(model, optimizer):\n",
        "    model.train()\n",
        "    losses = 0\n",
        "\n",
        "    # train_iter = TensorDataset(train_iter_src, train_iter_tgt)\n",
        "\n",
        "    train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
        "    for src, tgt in train_dataloader:\n",
        "      src = src.to(DEVICE)\n",
        "      tgt = tgt.to(DEVICE)\n",
        "\n",
        "      tgt_input = tgt[:-1, :]\n",
        "\n",
        "      src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "\n",
        "      logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      tgt_out = tgt[1:, :]\n",
        "      x=tgt_out.type(torch.LongTensor)\n",
        "      x=x.to(DEVICE)\n",
        "      loss = loss_fn(logits.reshape(-1, logits.shape[-1]), x.reshape(-1))\n",
        "      loss.backward()\n",
        "\n",
        "      optimizer.step()\n",
        "      losses += loss.item()\n",
        "\n",
        "    return losses / len(list(train_dataloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        },
        "id": "HngMSVin8l_H",
        "outputId": "28244382-522c-4e5a-c641-04aa50f3824a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5076: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 13, Train loss: 5.048, Val loss: 0.000, Epoch time = 1827.326s\n",
            "Epoch: 14, Train loss: 4.985, Val loss: 0.000, Epoch time = 1832.816s\n",
            "Epoch: 15, Train loss: 4.945, Val loss: 0.000, Epoch time = 1822.759s\n",
            "Epoch: 16, Train loss: 5.038, Val loss: 0.000, Epoch time = 1816.461s\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-094c2d6f5250>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'/content/drive/MyDrive/your_model{epoch-1}.pth'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'/content/drive/MyDrive/your_model{epoch}.pth'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-fd8e2088f9e9>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, optimizer)\u001b[0m\n\u001b[1;32m     44\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from timeit import default_timer as timer\n",
        "NUM_EPOCHS = 0\n",
        "\n",
        "\n",
        "for epoch in range(13, 18+1):\n",
        "    start_time = timer()\n",
        "    if epoch!=1:\n",
        "      model_path = f'/content/drive/MyDrive/your_model{epoch-1}.pth'\n",
        "      transformer.load_state_dict(torch.load(model_path))\n",
        "    train_loss = train_epoch(transformer, optimizer)\n",
        "    end_time = timer()\n",
        "    model_path = f'/content/drive/MyDrive/your_model{epoch}.pth'\n",
        "    torch.save(transformer.state_dict(), model_path)\n",
        "    # val_loss = evaluate(transformer)\n",
        "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {0:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hl1l7i3rI82T"
      },
      "outputs": [],
      "source": [
        "# function to generate output sequence using greedy algorithm\n",
        "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
        "    src = src.to(DEVICE)\n",
        "    src_mask = src_mask.to(DEVICE)\n",
        "\n",
        "    memory = model.encode(src, src_mask)\n",
        "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
        "    for i in range(max_len-1):\n",
        "        memory = memory.to(DEVICE)\n",
        "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
        "                    .type(torch.bool)).to(DEVICE)\n",
        "        out = model.decode(ys, memory, tgt_mask)\n",
        "        out = out.transpose(0, 1)\n",
        "        prob = model.generator(out[:, -1])\n",
        "        _, next_word = torch.max(prob, dim=1)\n",
        "        next_word = next_word.item()\n",
        "\n",
        "        ys = torch.cat([ys,\n",
        "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
        "        if next_word == EOS_IDX:\n",
        "            break\n",
        "    return ys\n",
        "\n",
        "\n",
        "# actual function to translate input sentence into target language\n",
        "def translate(model: torch.nn.Module, src_sentence: str):\n",
        "    model.eval()\n",
        "    src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n",
        "    num_tokens = src.shape[0]\n",
        "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
        "    tgt_tokens = greedy_decode(\n",
        "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
        "    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Q2IgAgbUKUF"
      },
      "outputs": [],
      "source": [
        "# print(translate(transformer, \"Eine Gruppe von Menschen steht vor einem Iglu .\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhKNDXofUX4M"
      },
      "outputs": [],
      "source": [
        "def results(Transformer,lang):\n",
        "  source_sentence,_,ids = extract_data(lang , '/content/drive/MyDrive/drive/Test_data2_final.json')\n",
        "  with open(f'{lang}1.csv', mode='w', newline='') as csv_file:\n",
        "    # Create a CSV writer object\n",
        "    csv_writer = csv.writer(csv_file)\n",
        "\n",
        "    # Write data to the CSV file\n",
        "    csv_writer.writerow(['Id', 'Translation'])\n",
        "\n",
        "    for sentence,id in zip(source_sentence,ids):\n",
        "      words = translate(transformer,sentence)\n",
        "      csv_writer.writerow([id,words])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnuhGPfPUv-t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d539266a-f53e-4f30-ef3e-828d78855fcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Language Pair: English-Bengali\n",
            "Language Pair: English-Gujarati\n",
            "Language Pair: English-Hindi\n",
            "Language Pair: English-Kannada\n",
            "Language Pair: English-Malayalam\n",
            "  Data Type: Test\n",
            "Language Pair: English-Tamil\n",
            "Language Pair: English-Telgu\n",
            "Language Pair: English-Bengali\n",
            "Language Pair: English-Gujarati\n",
            "Language Pair: English-Hindi\n",
            "Language Pair: English-Kannada\n",
            "Language Pair: English-Malayalam\n",
            "Language Pair: English-Tamil\n",
            "  Data Type: Test\n",
            "Language Pair: English-Telgu\n"
          ]
        }
      ],
      "source": [
        "model_path = f'/content/drive/MyDrive/your_model16.pth'\n",
        "transformer.load_state_dict(torch.load(model_path))\n",
        "for t in range(5,7):\n",
        "  results(transformer,LANGUAGES[t])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fr6ElHMqoSky"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}